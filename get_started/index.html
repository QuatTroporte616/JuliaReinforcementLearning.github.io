<!doctype html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-149861753-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-149861753-1');
</script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="icon" href="/assets/site/logo.svg">

  
   <link rel="stylesheet" href="/libs/highlight/github.min.css">
   

  <title>A Whirlwind Tour of ReinforcementLearning.jl</title>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
      integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
  <link href="/css/custom.css" rel="stylesheet">

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>

  <!-- distill -->
  <script src="/libs/distill/template.v2.8.0.js"></script>
  <d-front-matter>
    <script id="distill-front-matter" type="text/json">
        {
    "authors": [
        {
            "author":"Jun Tian",
            "authorURL":"https://github.com/findmyway",
            "affiliation":"",
            "affiliationURL":""
        }
    ],
    "publishedDate":"2020-06-18T12:36:15.000+08:00",
    "citationText":"Jun Tian, 2020"
}
    </script>
</d-front-matter>

</head>
<body>
  <nav class="navbar navbar-expand-lg  navbar-dark fixed-top" style="background-color: #1fd1f9; background-image: linear-gradient(315deg, #1fd1f9 0%, #b621fe 74%); " id="mainNav">
  <div class="container">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarTogglerDemo01" aria-controls="navbarTogglerDemo01" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarTogglerDemo01">
      <span class="navbar-brand">
          <a class="navbar-brand" href="/">
            <!-- <img src="/assets/site/logo.svg" width="30" height="30" alt="logo" loading="lazy"> -->
            JuliaReinforcementLearning
          </a>
      </span>

      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="/get_started/">Get Started</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/guide/">Guide</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://JuliaReinforcementLearning.github.io/ReinforcementLearning.jl/latest/">Doc</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/JuliaReinforcementLearning">Github</a>
        </li>
      </ul>
    </div>
</nav>

    <d-title><h1>A Whirlwind Tour of ReinforcementLearning.jl</h1><p>Welcome to the world of reinforcement learning in Julia. Now let&#39;s get started in 3 lines&#33;</p>
</d-title>
    <d-byline></d-byline>
    
<!-- Content appended here -->
<d-article class="franklin-content"><h2 id="prepare"><a href="#prepare">Prepare</a></h2>
<p>First things first, <a href="https://julialang.org/downloads/">download</a> and install the latest stable Julia version. ReinforcementLearning.jl is tested on all platforms, so just choose the one you are familiar with. If you already have Julia installed, please make sure that it is <code>v1.3</code> or above.</p>
<aside>ReinforcementLearning.jl relies on some features introduced since <code>v1.3</code>, like <a href="https://docs.julialang.org/en/v1/base/multi-threading/index.html">MultiThreading</a>, and <a href="https://julialang.github.io/Pkg.jl/dev/artifacts/">Artifacts</a></aside>
<p>Another useful tool is <a href="https://github.com/tensorflow/tensorboard">tensorboard</a> <d-footnote>You don&#39;t need to install the whole TensorFlow to use the TensorBoard. Behind the scene, ReinforcementLearning.jl uses <a href="https://github.com/PhilipVinc/TensorBoardLogger.jl">TensorBoardLogger.jl</a> to write data into the format that TensorBoard recoganizes.</d-footnote>. You can install it via <code>pip install tensorboard</code> with the python package installer <a href="https://pip.pypa.io/en/stable/installing/"><code>pip</code></a>.</p>
<h2 id="get_started"><a href="#get_started">Get Started</a></h2>
<p>Run <code>julia</code> in the command line &#40;or double-click the Julia executable&#41; and now you are in an interactive session &#40;also known as a read-eval-print loop or &quot;REPL&quot;&#41;. Then execute the following code:</p>
<pre><code class="julia hljs">julia&gt; ] add ReinforcementLearning

julia&gt; <span class="hljs-keyword">using</span> ReinforcementLearning

julia&gt; run(E<span class="hljs-string">`JuliaRL_BasicDQN_CartPole`</span>);</code></pre>
<p>So what&#39;s happening here?</p>
<ol>
<li><p>In the first line, typing <code>&#93;</code> will bring you to the <em>Pkg</em> mode. <code>add ReinforcementLearning</code> will install the latest version of <code>ReinforcementLearning.jl</code> for you. And then remember to press backspace or ^C to get back to the normal mode.</p>
</li>
<li><p><code>using ReinforcementLearning</code> will bring the names exported in <code>ReinforcementLearning</code> into global scope. If this is your first time to run, you&#39;ll see <em>precompiling ReinforcementLearning</em>. And it may take a while.</p>
</li>
<li><p>The third line means, <code>run</code> an <strong>E</strong>xperiment named <code>JuliaRL_BasicDQN_CartPole</code>.</p>
</li>
</ol>
<p>CartPole is considered to be one of the simplest environments for <strong>DRL&#40;Deep Reinforcement Learning&#41;</strong> algorithms testing. The state of the CartPole environment can be described with 4 numbers and the actions are two integers&#40;<code>1</code> and <code>2</code>&#41;. Before game terminates, agent can gain a reward of <code>&#43;1</code> for each step. And the game will be forced to end after 200 steps, thus the maximum reward of an episode is <strong>200</strong>. </p>
<p>While the experiment is running, you&#39;ll see the following information and a progress bar. The information may be slightly different based on your platform and your current working directory. Note that the first run would be slow. On a mordern computer, the experiment should be finished in a minute.</p>

<pre><code class="plaintext hljs">LoadError: UndefVarError: @E_cmd not defined
in expression starting at none:1
</code></pre>
<p>Follow the instruction above and run <code>tensorboard --logdir /the/path/shown/above</code> and a link will be prompted &#40;typically it&#39;s <code>http://YourHost:6006/</code>&#41;. Now open it in your browser, you&#39;ll see a webpage like the following one:</p>
<figure class="l-page text-center">
    <img src="/assets/get_started/tensorboard_demo.png">
    <figcaption>Here two important varialbes are logged: training <strong>loss</strong> per update and total <strong>reward</strong> of each episode during training. As you can see, our agent can reach the maximum reward after training for about 4k steps.</figcaption>
</figure>

<h2 id="exercise"><a href="#exercise">Exercise</a></h2>
<p>Now that you already know how to run the experiment of <a href="https://juliareinforcementlearning.org/ReinforcementLearning.jl/latest/rl_zoo/#ReinforcementLearningZoo.BasicDQNLearner">BasicDQN</a> algorithm with the CartPole environment. You are suggested to try some other algorithms <d-footnote>For the full list of supported algorithms, please visit <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningZoo.jl">ReinforcementLearningZoo.jl</a></d-footnote>:</p>
<ul>
<li><p><code>JuliaRL_DQN_CartPole</code></p>
</li>
<li><p><code>JuliaRL_PrioritizedDQN_CartPole</code></p>
</li>
<li><p><code>JuliaRL_Rainbow_CartPole</code></p>
</li>
<li><p><code>JuliaRL_IQN_CartPole</code></p>
</li>
<li><p><code>JuliaRL_A2C_CartPole</code></p>
</li>
<li><p><code>JuliaRL_A2CGAE_CartPole</code></p>
</li>
<li><p><code>JuliaRL_PPO_CartPole</code></p>
</li>
<li><p><code>JuliaRL_DDPG_Pendulum</code></p>
</li>
</ul>
<h2 id="basic_components"><a href="#basic_components">Basic Components</a></h2>
<p>&#91;WIP&#93;<!-- this is necessary!!! not sure why... -->
<div></div></d-article><!-- CONTENT ENDS HERE -->
          <!-- <d-bibliography src="bibliography.bib"></d-bibliography> -->

    
    
        


    

    <d-appendix>
    <h3>Corrections</h3>
<p>If you see mistakes or want to suggest changes, please <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io/issues">create an issue</a> on the source repository.</p>

    
</d-appendix>

    <div class="distill-site-nav distill-site-footer">
      <div class="row">
        <div class="col-md-3"></div>
        <div class="col-md-6">
          <p>This website is built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> with the <a href="https://github.com/tlienart/DistillTemplate">DistillTemplate</a> (licensed under <a href="https://github.com/distillpub/template/blob/master/LICENSE">Apache License 2.0</a>) and <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a>. The <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io">source code</a> of this website is licensed under <a href="https://github.com/JuliaReinforcementLearning/JuliaReinforcementLearning.github.io/blob/master/LICENSE">MIT License</a>. The <a href="https://github.com/JuliaReinforcementLearning">JuliaReinforcementLearning</a> organization was first created by <a href="https://github.com/jbrea">Johanni Brea</a> and then co-maintained by <a href="https://github.com/findmyway">Jun Tian</a>. And we thank all the contributors <sup>[<a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl/graphs/contributors">1</a>, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningBase.jl/graphs/contributors">2</a>, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningCore.jl/graphs/contributors">3</a>, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningZoo.jl/graphs/contributors">4</a>, <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningEnvironments.jl/graphs/contributors">5</a>, <a href="https://github.com/JuliaReinforcementLearning/ArcadeLearningEnvironment.jl/graphs/contributors">6</a>]</sup> in this organization.</p>
        </div>
        <div class="col-md-3"></div>
      </div>
    </div>
  </body>
</html>
